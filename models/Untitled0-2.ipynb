{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-9kmJuMrtaDV"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Подключение Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Папки с данными\n",
        "train_dir = '/content/dataset/train'\n",
        "val_dir = '/content/dataset/val'\n",
        "\n",
        "# 3. Импорты\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "# 4. Параметры\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS_TOP = 5        # Сначала обучаем только верхушку\n",
        "EPOCHS_FINE_TUNE = 20 # Потом дообучаем всю сеть\n",
        "\n",
        "# 5. Загрузчики данных\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# 6. Модель\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n",
        "base_model.trainable = False  # сначала замораживаем\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# 7. Компиляция и обучение только верхушки\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"Обучаем только верхние слои...\")\n",
        "history_top = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=EPOCHS_TOP\n",
        ")\n",
        "\n",
        "# 8. Разморозка EfficientNet\n",
        "print(\"Размораживаем всю модель...\")\n",
        "base_model.trainable = True\n",
        "\n",
        "# Обычно уменьшают скорость обучения после разморозки\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 9. Дообучение всей модели\n",
        "print(\"Дообучаем всю модель...\")\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=EPOCHS_FINE_TUNE\n",
        ")\n",
        "\n",
        "# 10. Сохранение\n",
        "model.save('/content/drive/MyDrive/weed_model_efficientnet.keras')\n",
        "print(\"✅ Модель полностью обучена и сохранена!\")\n"
      ],
      "metadata": {
        "id": "d3qD0_Gyw8pN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10151abf-abf3-4352-c95d-24709de0c754"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 1461 images belonging to 5 classes.\n",
            "Found 755 images belonging to 5 classes.\n",
            "Обучаем только верхние слои...\n",
            "Epoch 1/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 291ms/step - accuracy: 0.2013 - loss: 1.6285 - val_accuracy: 0.3245 - val_loss: 1.5102\n",
            "Epoch 2/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.2544 - loss: 1.5749 - val_accuracy: 0.3245 - val_loss: 1.5235\n",
            "Epoch 3/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.2459 - loss: 1.5733 - val_accuracy: 0.3245 - val_loss: 1.5148\n",
            "Epoch 4/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.2726 - loss: 1.5748 - val_accuracy: 0.3245 - val_loss: 1.5301\n",
            "Epoch 5/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 67ms/step - accuracy: 0.2474 - loss: 1.5778 - val_accuracy: 0.3245 - val_loss: 1.5147\n",
            "Размораживаем всю модель...\n",
            "Дообучаем всю модель...\n",
            "Epoch 1/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 740ms/step - accuracy: 0.2738 - loss: 1.7347 - val_accuracy: 0.3245 - val_loss: 1.5683\n",
            "Epoch 2/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - accuracy: 0.5319 - loss: 1.2334 - val_accuracy: 0.3245 - val_loss: 1.5680\n",
            "Epoch 3/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 99ms/step - accuracy: 0.7105 - loss: 0.9192 - val_accuracy: 0.3245 - val_loss: 1.5366\n",
            "Epoch 4/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7911 - loss: 0.7278 - val_accuracy: 0.3563 - val_loss: 1.4794\n",
            "Epoch 5/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 98ms/step - accuracy: 0.8411 - loss: 0.5868 - val_accuracy: 0.4238 - val_loss: 1.3009\n",
            "Epoch 6/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 100ms/step - accuracy: 0.8738 - loss: 0.4833 - val_accuracy: 0.6781 - val_loss: 0.9657\n",
            "Epoch 7/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.8964 - loss: 0.3938 - val_accuracy: 0.8570 - val_loss: 0.5817\n",
            "Epoch 8/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 97ms/step - accuracy: 0.9040 - loss: 0.3515 - val_accuracy: 0.9126 - val_loss: 0.3671\n",
            "Epoch 9/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - accuracy: 0.9142 - loss: 0.3135 - val_accuracy: 0.9523 - val_loss: 0.2765\n",
            "Epoch 10/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 100ms/step - accuracy: 0.9124 - loss: 0.2824 - val_accuracy: 0.9536 - val_loss: 0.2090\n",
            "Epoch 11/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 96ms/step - accuracy: 0.9258 - loss: 0.2633 - val_accuracy: 0.9603 - val_loss: 0.1914\n",
            "Epoch 12/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - accuracy: 0.9491 - loss: 0.2116 - val_accuracy: 0.9576 - val_loss: 0.1568\n",
            "Epoch 13/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - accuracy: 0.9504 - loss: 0.1765 - val_accuracy: 0.9616 - val_loss: 0.1399\n",
            "Epoch 14/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - accuracy: 0.9329 - loss: 0.1958 - val_accuracy: 0.9695 - val_loss: 0.1208\n",
            "Epoch 15/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 97ms/step - accuracy: 0.9589 - loss: 0.1595 - val_accuracy: 0.9629 - val_loss: 0.1325\n",
            "Epoch 16/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - accuracy: 0.9571 - loss: 0.1594 - val_accuracy: 0.9510 - val_loss: 0.1451\n",
            "Epoch 17/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.9690 - loss: 0.1298 - val_accuracy: 0.9338 - val_loss: 0.1835\n",
            "Epoch 18/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - accuracy: 0.9554 - loss: 0.1300 - val_accuracy: 0.9669 - val_loss: 0.1309\n",
            "Epoch 19/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 102ms/step - accuracy: 0.9566 - loss: 0.1484 - val_accuracy: 0.9735 - val_loss: 0.0940\n",
            "Epoch 20/20\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.9756 - loss: 0.1092 - val_accuracy: 0.9762 - val_loss: 0.0880\n",
            "✅ Модель полностью обучена и сохранена!\n"
          ]
        }
      ]
    }
  ]
}